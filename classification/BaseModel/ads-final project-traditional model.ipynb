{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfb/O2CAzhBGduFQlhbSAg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Clone the ESC-50 dataset"],"metadata":{"id":"6faZK_YbxqD-"}},{"cell_type":"code","source":["!git clone https://github.com/karolpiczak/ESC-50.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrNi1KYo-4nL","executionInfo":{"status":"ok","timestamp":1683511522445,"user_tz":240,"elapsed":199,"user":{"displayName":"Yuxin Chen","userId":"17502738699833578177"}},"outputId":"3c1473a3-ff74-48f6-a38d-692bc739d2d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'ESC-50' already exists and is not an empty directory.\n"]}]},{"cell_type":"markdown","source":["#Data Loader for ESC-50 dataset"],"metadata":{"id":"S8p7KGaOIYnZ"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import torchaudio\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","import os\n","import pandas as pd\n","import torchaudio\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","\n","#class in version allows for duration setting: applying data augmentation\n","#turns out waveform of audio files with fixed hertz rate:22050\n","class ESC50Dataset(Dataset):\n","    def __init__(self, path, meta_file, duration=8.0, transform=None):\n","        self.path = path\n","        self.meta = pd.read_csv(meta_file)\n","        self.duration = duration\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.meta)\n","\n","    def __getitem__(self, idx):\n","        audio_path = os.path.join(self.path, self.meta.iloc[idx, 0])\n","        label = self.meta.iloc[idx, 1]\n","        waveform, sr = torchaudio.load(audio_path)\n","        if sr != 22050:\n","            waveform = torchaudio.transforms.Resample(sr, 22050)(waveform)\n","            sr = 22050\n","        length = int(self.duration * sr)\n","        if waveform.shape[1] < length:\n","            waveform = torch.nn.functional.pad(waveform, (0, length - waveform.shape[1]))\n","        else:\n","            waveform = waveform[:, :length]\n","        if self.transform:\n","            waveform = self.transform(waveform)\n","        return waveform, label\n"],"metadata":{"id":"8wFy16YSL-qm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Preprocessing"],"metadata":{"id":"LOoq1YpaIUmT"}},{"cell_type":"code","source":["#we choose STFT as our input representaion\n","#turn the 1 dimensional time-domain waveform into STFT: 2 dimensional time-frequency domain\n","class STFTDataset(ESC50Dataset):\n","    def __init__(self, path, meta_file, duration=8.0, transform=None):\n","        super().__init__(path, meta_file, duration, transform)\n","\n","    def __getitem__(self, idx):\n","        waveform, label = super().__getitem__(idx)\n","        stft = torch.stft(waveform, n_fft=512, hop_length=256, win_length=512, return_complex=True)\n","        stft = torch.abs(stft)  # Compute the magnitude of STFT\n","        stft = stft.transpose(1, 2)  # Swap time and frequency dimensions\n","        return stft, label"],"metadata":{"id":"OgCYOTxLkzve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Train and test set"],"metadata":{"id":"0Yfplk4GIiM4"}},{"cell_type":"code","source":["#split data into train and test set\n","root = \"ESC-50/audio/\"\n","meta_file = \"ESC-50/meta/esc50.csv\"\n","dataset = STFTDataset(root, meta_file)\n","\n","import random\n","#can adjust input fraction: allow to train in our local machine\n","fraction = 0.05\n","train_data, valid_data = train_test_split(dataset, test_size=0.2, random_state=42, stratify=dataset.meta[\"target\"])\n","\n","# Limit the dataset size\n","train_data = random.sample(train_data, int(len(train_data) * fraction))\n","valid_data = random.sample(valid_data, int(len(valid_data) * fraction))\n","\n","train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=4)\n","valid_loader = DataLoader(valid_data, batch_size=8, shuffle=False, num_workers=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZBaVkMVk35N","executionInfo":{"status":"ok","timestamp":1683511561631,"user_tz":240,"elapsed":28399,"user":{"displayName":"Yuxin Chen","userId":"17502738699833578177"}},"outputId":"c0685baa-20c9-4fb0-f509-a8730a91cd29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"markdown","source":["# Model: build up our HarmonicCNN"],"metadata":{"id":"pnrVNu1lIMv4"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","\n","class Conv_2d(nn.Module):\n","    def __init__(self, in_channels, out_channels, pooling=None):\n","        super(Conv_2d, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, (3,3), stride=1, padding=(1,1))\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.pool = None\n","        if pooling is not None:\n","            self.pool = nn.MaxPool2d(pooling)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = F.relu(x)\n","        if self.pool is not None:\n","            x = self.pool(x)\n","        return x\n","\n","class Res_2d(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(Res_2d, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, (3,3), stride=1, padding=(1,1))\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, (3,3), stride=1, padding=(1,1))\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        if in_channels != out_channels:\n","            self.conv_skip = nn.Conv2d(in_channels, out_channels, (1,1), stride=1, padding=(0,0))\n","        else:\n","            self.conv_skip = None\n","\n","    def forward(self, x):\n","        skip = x\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","\n","        if self.conv_skip is not None:\n","            skip = self.conv_skip(skip)\n","\n","        x += skip\n","        x = F.relu(x)\n","\n","        return x\n","\n","class HarmonicCNN2D(nn.Module):\n","    def __init__(self,\n","                n_channels=128,\n","                sample_rate=16000,\n","                n_fft=512,\n","                f_min=0.0,\n","                f_max=8000.0,\n","                n_mels=128,\n","                n_class=50,\n","                n_harmonic=6,\n","                semitone_scale=2,\n","                learn_bw='only_Q'):\n","        super(HarmonicCNN2D, self).__init__()\n","\n","        # Harmonic STFT\n","        self.hstft = nn.Sequential(\n","            nn.Conv2d(1, n_harmonic, (7,7), stride=1, padding=(3,3)),\n","            nn.BatchNorm2d(n_harmonic),\n","            nn.ReLU(),\n","            nn.Conv2d(n_harmonic, n_harmonic, (5,5), stride=1, padding=(2,2)),\n","            nn.BatchNorm2d(n_harmonic),\n","            nn.ReLU(),\n","            nn.Conv2d(n_harmonic, n_harmonic, (3,3), stride=1, padding=(1,1)),\n","            nn.BatchNorm2d(n_harmonic),\n","            nn.ReLU(),\n","            nn.Conv2d(n_harmonic, n_harmonic, (3,3), stride=1, padding=(1,1)),\n","            nn.BatchNorm2d(n_harmonic),\n","            nn.ReLU()\n","        )\n","\n","        # CNN\n","        self.layer1 = Conv_2d(n_harmonic, n_channels, pooling=2)\n","        self.layer2 = Res_2d(n_channels, n_channels)\n","        self.layer3 = Res_2d(n_channels, n_channels)\n","        self.layer4 = Res_2d(n_channels, n_channels)\n","        self.layer5 = Conv_2d(n_channels, n_channels*2, pooling=(2,3))\n","        self.layer6 = Res_2d(n_channels*2, n_channels*2)\n","        self.layer7 = Res_2d(n_channels*2, n_channels*2)\n","\n","        # Dense\n","        self.dense1 = nn.Linear(n_channels*2, n_channels*2)\n","        self.bn = nn.BatchNorm1d(n_channels*2)\n","        self.dense2 = nn.Linear(n_channels*2, n_class)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        # Spectrogram\n","        x = self.hstft(x)\n","\n","        # CNN\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = x.squeeze(2)\n","\n","        # Global Max Pooling\n","        x = nn.AdaptiveMaxPool2d((1, 1))(x)\n","        x = torch.flatten(x, 1)\n","\n","        # Dense\n","        x = self.dense1(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.dense2(x)\n","        x = nn.Sigmoid()(x)\n","\n","        return x\n"],"metadata":{"id":"KK016zofEAxW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Define train and validation methods"],"metadata":{"id":"2E2k4JYvIEJv"}},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","def train(model, loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","    \n","    progress_bar = tqdm(loader, desc=\"Training\", ncols=100)\n","    \n","    for inputs, targets in progress_bar:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","        #Update the progress bar\n","        progress_bar.set_postfix({\"Loss\": running_loss / (total // loader.batch_size), \"Accuracy\": 100 * correct / total})\n","    \n","    progress_bar.close()\n","    \n","    accuracy = 100 * correct / total\n","    return running_loss / len(loader), accuracy\n"],"metadata":{"id":"EMdQAamtSKwi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, loader, criterion, device):\n","    model.eval()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","    \n","    progress_bar = tqdm(loader, desc=\"Validation\", ncols=100)\n","    \n","    with torch.no_grad():\n","        for inputs, targets in progress_bar:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","\n","            # Update the progress bar\n","            progress_bar.set_postfix({\"Loss\": running_loss / (total // loader.batch_size), \"Accuracy\": 100 * correct / total})\n","    \n","    progress_bar.close()\n","    \n","    accuracy = 100 * correct / total\n","    return running_loss / len(loader), accuracy\n"],"metadata":{"id":"yjd8_ssgSNdY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Start training"],"metadata":{"id":"-4CvmlUIH_GB"}},{"cell_type":"code","source":["from torch.optim import Adam\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#model = HarmonicCNN().to(device)\n","model = HarmonicCNN2D()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=0.001)\n","\n","num_epochs = 50\n","for epoch in range(1, num_epochs + 1):\n","    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer, device)\n","    valid_loss, valid_accuracy = validate(model, valid_loader, criterion, device)\n","\n","    print(f'Epoch: {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":836},"id":"PbtKTB9ZM3zk","outputId":"34352b06-6a85-437d-bb53-9c65b89f26e9","executionInfo":{"status":"error","timestamp":1683520031599,"user_tz":240,"elapsed":8469980,"user":{"displayName":"Yuxin Chen","userId":"17502738699833578177"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Training: 100%|███████████████████████████| 10/10 [16:08<00:00, 96.87s/it, Loss=3.81, Accuracy=12.5]\n","Validation: 100%|█████████████████████████████| 3/3 [01:14<00:00, 24.67s/it, Loss=5.47, Accuracy=25]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1/50, Train Loss: 3.8132, Train Acc: 12.50%, Valid Loss: 3.6457, Valid Acc: 25.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|█████████████████████████████| 10/10 [15:52<00:00, 95.26s/it, Loss=3.58, Accuracy=25]\n","Validation: 100%|█████████████████████████████| 3/3 [01:17<00:00, 25.68s/it, Loss=5.11, Accuracy=20]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2/50, Train Loss: 3.5814, Train Acc: 25.00%, Valid Loss: 3.4066, Valid Acc: 20.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|█████████████████████████████| 10/10 [15:38<00:00, 93.87s/it, Loss=3.42, Accuracy=15]\n","Validation: 100%|█████████████████████████████| 3/3 [01:17<00:00, 25.88s/it, Loss=4.93, Accuracy=15]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3/50, Train Loss: 3.4213, Train Acc: 15.00%, Valid Loss: 3.2840, Valid Acc: 15.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|███████████████████████████| 10/10 [15:32<00:00, 93.30s/it, Loss=3.31, Accuracy=17.5]\n","Validation: 100%|██████████████████████████████| 3/3 [01:15<00:00, 25.23s/it, Loss=4.86, Accuracy=5]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4/50, Train Loss: 3.3059, Train Acc: 17.50%, Valid Loss: 3.2395, Valid Acc: 5.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|█████████████████████████████| 10/10 [15:39<00:00, 93.91s/it, Loss=3.31, Accuracy=15]\n","Validation: 100%|█████████████████████████████| 3/3 [01:17<00:00, 25.85s/it, Loss=4.81, Accuracy=10]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5/50, Train Loss: 3.3071, Train Acc: 15.00%, Valid Loss: 3.2065, Valid Acc: 10.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|███████████████████████████| 10/10 [16:02<00:00, 96.25s/it, Loss=3.24, Accuracy=18.8]\n","Validation: 100%|█████████████████████████████| 3/3 [01:17<00:00, 25.91s/it, Loss=4.76, Accuracy=20]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6/50, Train Loss: 3.2425, Train Acc: 18.75%, Valid Loss: 3.1720, Valid Acc: 20.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|███████████████████████████| 10/10 [15:35<00:00, 93.52s/it, Loss=3.19, Accuracy=26.2]\n","Validation: 100%|█████████████████████████████| 3/3 [01:17<00:00, 25.72s/it, Loss=4.75, Accuracy=25]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7/50, Train Loss: 3.1891, Train Acc: 26.25%, Valid Loss: 3.1688, Valid Acc: 25.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|███████████████████████████| 10/10 [15:39<00:00, 93.95s/it, Loss=3.18, Accuracy=27.5]\n","Validation: 100%|█████████████████████████████| 3/3 [01:17<00:00, 25.67s/it, Loss=4.71, Accuracy=25]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8/50, Train Loss: 3.1776, Train Acc: 27.50%, Valid Loss: 3.1414, Valid Acc: 25.00%\n"]},{"output_type":"stream","name":"stderr","text":["Training:  20%|█████▍                     | 2/10 [04:46<19:05, 143.23s/it, Loss=3.19, Accuracy=37.5]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-0368a5e9feba>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-fca9e69930cd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}